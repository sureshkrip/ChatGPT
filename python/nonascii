from pyspark.sql.functions import udf
from pyspark.sql.types import BooleanType

def has_non_ascii_chars(s):
    try:
        s.encode('ascii')
    except UnicodeEncodeError:
        return True
    else:
        return False

udf_has_non_ascii_chars = udf(has_non_ascii_chars, BooleanType())

2/28/2023
# assuming your DataFrame has a column called 'text'
df_filtered = df.filter(~udf_has_non_ascii_chars('text'))

from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("ReadCSV").getOrCreate()

df = spark.read.format("csv").option("header", "true").option("charset", "ascii").load("path/to/csv/file.csv")

df.show()


from pyspark.sql import SparkSession
import codecs

spark = SparkSession.builder.appName("ReadCSV").getOrCreate()

try:
    with codecs.open("path/to/csv/file.csv", "r", encoding="utf-8") as f:
        df = spark.read.csv(f, header=True)
except UnicodeDecodeError as e:
    raise Exception("Error reading CSV file: %s" % str(e))

df.show()


